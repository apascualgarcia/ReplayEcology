

## README


This repository contains scripts and data to reproduce results of the [article](https://doi.org/10.1101/2023.07.07.548163):

```
Pascual-García, A., Rivett, D., Jones, M. L., & Bell, T. (2023). Replaying the tape of ecology to domesticate wild microbiomes. bioRxiv, 2023-07. (https://doi.org/10.1101/2023.07.07.548163)
```

First release was permanently stored in [![DOI](https://zenodo.org/badge/627513792.svg)](https://zenodo.org/doi/10.5281/zenodo.13785758).

### Organization of the repository

#### Folders
The repository has a folder containing all the scripts (`src`) and several folders for the data. It is necessary to keep this structure to execute the scripts. Folders labelled 1 to 6 are used sequentially for dada2 pipeline, with final ASV tables available in folder number 6. Folders labelled 7 contain analysis related to microbial composition. Folder 8 contains PICRUSt analysis and folder 9 the predictions obtained after optimal superposition.

#### Files excluded

To keep the repository as light as possible, a number of files were excluded. These files can be regenerated using the scripts provided.

* Folders 0 to 3 are completely empty because they should contain the raw sequencing data and a number of large output files from dada2.
* The following files are also excluded (included in `.gitignore`):
    * `dada_output.RDS`, `seqtab.csv` and `seqtab.nochim.csv`.
    * `silva*`.
    * `4_dada2/DECIPHER_2.20.0`
    * `5_treeholes/seqtab_treeholes.csv`
    * `8_PICRUSt2/KO_metagenome_out/pred_metagenome_unstrat.tsv` (A bzip2 compressed file with the same name is available)
    * Intermediate files generated by PICRUSt (`8_PiCRUST/intermediate`).
    * All figures (extension `*pdf`).

### Input data

* Sequences associated with this study are deposited at NCBI under **BioProject accession number PRJNA989519**. This project contains the 16S rRNA amplicon sequencing data associated with each of the communities at day 0
**(SUB13586664)**, as well as at day 7 for the four replicate growth experiments **(SUB13586665-8)**. Additionally, the project contains samples associated with other projects and/or run on the same sequencing runs **(SUB13586669-SUB13586671)**, which should also be downloaded and run through the DADA2 pipeline with the sequences related to this study, if one desires to reproduce this analysis exactly.

* Users interested in reproducing the whole pipeline should download all the FASTQ files deposited at NCBI to their respective folders in `3_filtered`

* Users interested in the processed data will find:
    * `metadata_Time0D-7D-4M_May2022.csv`: starting metadata table, found in directory `4_dada2`. During the analysis, this table will be extended. Therefore, other metadata tables can be found in subsequent folders.
    * `seqtable_readyforanalysis.csv`: ASV vs samples table, found in directory `6_finalfiles`.
    * `taxa_wsp_readyforanalysis.csv`: Taxonomy, also found in directory `6_finalfiles`.

#### Description metadata table

The most comprehensive metadata table possibly is `metadata_Time0D-7D-4M_May2022_wJSDpart_ext.csv`, located in the directory `7.3_phyloseq/`. Please note that this metadata contains information of samples used in experiments related to these communities but not presented in this work. In addition, all starting communities presented in Pascual-García & Bell, _Nature Commun._ 2020 are also available in this repository, although only a subset of them were revived for this work. We describe below how to identify this subset.

Metadata contain the following fields:

* `sampleid`: Id of samples
* `Name.2`: Alternative Id for some samples **(not used in this work)**
* `Community`: **Ignore, not used in this work.**
* `Species`: **Ignore, not used in this work.**
* `replicate`: Replicate of the experiment. Starting communities are labelled as Rep0
* `BreakingBag`: **Ignore, not used in this work.**
* `parent`: ID of the starting communities from which final communities departed. For example, final community with id `WYT14.1` is the replicate 1 of starting community `WYT14`, which is the ID indicated in this field.
* `Location`: Sampling field from which the starting communities were sampled.
* `Experiment`: Either starting communities (`0D`) or final communities (`7D_rep$`) were "$" = 1-4 depending on the replicate. **Samples belonging to experiment `4M` should be ignored.**
* `Part_Time0D_17`: Id of the class the starting communities belong to, corresponding to the maximum of the Calinski-Harabasz index found considering starting communities only. (1 to 17 and NA for samples not belonging to the set)
* `Part_Time0D_6`:  Id of the class the starting communities belong to, corresponding to the second maximum of the Calinski-Harabasz index found considering starting communities only (analysed in this work) (runs from 1 to 6 and NA for samples not belonging to the set)
* `Part_Time4M_64`:  **Ignore, not used in this work.**
* `Part_Time7D_rep1_2`: Id of the class the first replicate of final communities belong to, corresponding to the maximum of the Calinski-Harabasz index.  (1 to 2 and NA for samples not belonging to the set)
* `Part_Time7D_rep2_2`:  Id of the class the second replicate of final communities belong to, corresponding to the maximum of the Calinski-Harabasz index. (1 to 2 and NA for samples not belonging to the set)
* `Part_Time7D_rep3_2`:  Id of the class the third replicate of final communities belong to, corresponding to the maximum of the Calinski-Harabasz index. (1 to 2 and NA for samples not belonging to the set)
* `Part_Time7D_rep4_2`:  Id of the class the fourth replicate of final communities belong to, corresponding to the maximum of the Calinski-Harabasz index. (1 to 2 and NA for samples not belonging to the set)
* `replicate.partition`: Combination of the replicate and partition ids. Note that the ids obtained for each replicate independently (1 and 2 for each replicate) can be considered paired across replicates, since we showed they have similar compositions. Also note that Rep0.Class1 and Rep0.Class2 are ids used in Experiments `0D` and `4M`. Therefore, those belonging to `Experiment = 4M` should be ignored.
* `partition`: Only the class. As in the previous field, one should exclude samples in `Experiment = 4M`.
* `ExpCompact`: Another identifier for the experiment, in which the 4 replicates of final communities have the same id (note that in the field `Experiment` the different replicates were differentiated). Levels are `Starting`, `Final` (and `Evolved` should be excluded).
* `exp.replicate.partition`: Combination of `ExpCompact`, and `replicate.partition`
* `exp.partition`: Combination of `ExpCompact`, and `partition`


### Bioinformatic pipeline

Most scripts have a header describing their usage. All of them were coded considering the structure of the repository, so there is no need to modify the paths, hence are hard-coded relative to the root of the repository. Please note that to make the scripts portable,  R Projects and/or some functions to recover the user's path are used which, in the case of R scripts, require executing the script from RStudio. Some scripts have different options for the analysis, indicated in variables. 

#### _Preliminary processing steps_

Code for preliminary processing steps pre-ASV inference are **included in the repository for methodological transparency, but are not able to be run** because the necessary input files (sequence files at every stage of processing) have not been deposited in public repositories in order to avoid unnecessary use of data storage space (it is standard to deposit filtered sequence files for the purposes of reproducibility).

##### 1. Demultiplexing

Sequences for the 2844 samples were generated in two sequencing jobs performed by the sequencing company. Day 0 samples were included in the first job (052214DR16s), and day 7 samples in the second (021216DR515F), alongside samples from other projects in the lab group to which the 'day0' and 'day7' labels to not apply. These sequences were received from the sequencing company in batched files containing multiple samples, and hence needed to be demultiplexed using custom scripts.

* **scripts**: `demultiplex_day0.sh`; `demultiplex_day7.sh` - Scripts to demultiplex files received from sequencing company into one file per  individual samples.

* **inputs**: `1_raw/`

  - `day0`: *12 batch files for the first job (e.g. 052214DR16s-Sam1-80-pr.fastq)* -  These are not deposited in any public repository.
  - `day7`: *26 batch files for the second job (e.g. 021216DR515FSAM1-8a-pr.fastq)* - These are not deposited in any public repository.


* **outputs**: `2_demultiplexed/day0`;`2_demultiplexed/day7` - 2844 sequencing files for each sample (e.g. A01.AE49_052214DR16s-Sam476-550.fastq), deposited in two folders "day0" and "day7" (though note that files from other studies are included in each of these, to which this nomenclature does not apply).

##### 2. Removal of problematic reads

 A very small minority of the reads (i.e. 4 lines) in each of the demultiplexed FASTQ files had quality scores that were a different length to the sequences, which is apparently how they arrived from the sequencing company. This minor problem was restricted to day 0 data/first sequencing run, and online discussions suggest it was probably due to some minor file corruption (https://www.biostars.org/p/180310/; https://www.biostars.org/p/231090/; https://forum.qiime2.org/t/fastq-gz-and-quality-score-length-do-not-match-using-type-emppairedendsequences-from-miseq/14142/7), perhaps occurring at the sequencing center, and that these records can be removed. Therefore, we removed this very small minority of problematic reads from the demultiplexed FASTQs in order to enable downstream analysis with these FASTQs.

 * **scripts**: `remove_problematicreads.R` - Reads in the FASTQ files, compares sequence and quality lengths, then removes those the reads for which they don't match for each of the files.

 * **inputs**: `2_demultiplexed/day0`;`2_demultiplexed/day7` - 2844 sequencing files for each sample (e.g. A01.AE49_052214DR16s-Sam476-550.fastq), deposited in two folders "day0" and "day7" (though note again that files from other studies are included in each of these, to which this nomenclature does not apply).

 * **outputs**: `2_demultiplexed/corrected/day0`;`2_demultiplexed/corrected/day7` - 2844 corrected sequencing files for each sample (e.g. A01.AE49_052214DR16s-Sam476-550.fastq), deposited in two folders "day0" and "day7" (though note again that files from other studies are included in each of these, to which this nomenclature does not apply).

##### 3. Filtering using DADA2

This script runs the preliminary processing step of the DADA2 pipeline, filtering and trimming the sequences in the demultiplexed sequence files to prepare them for downstream work. The filtered sequences that result from this script are the most raw sequence data that we have made available via deposition at NCBI (BioProject accession number PRJNA989519). The is standard practice but also means that this script is not executable by external users, since only its outputs but not its inputs are available to external users.

* **script**: `dada2_filter_sequences.R` - This script filters and trims the 2844 sequencing files using standard parameters of DADA2, truncating reads at the first instance of a quality score less than 11 and after a length of 240 bases.

* **inputs**: `2_demultiplexed/corrected/day0`;`2_demultiplexed/corrected/day7` - 2844 corrected sequencing files for each sample (e.g. A01.AE49_052214DR16s-Sam476-550.fastq), deposited in two folders "day0" and "day7" (though note that files from other studies are included in each of these, to which this nomenclature does not apply).

* **outputs**: `3_filtered` - 2843 filtered sequencing files (e.g. day0_A01.AE49_052214DR16s-Sam476-550_filt.fastq). There is no filtered file for one sample (H11.BWd08_052214DR16s-Sam321-400-pr.fastq.gz) because there were no reads after filtering (https://github.com/benjjneb/dada2/issues/1279).

##### 4. Organising the files

The 2843 filtered sequence files were sorted into separate folders based on study and (for this study) replicate within study, in order to facilitate their deposition at NCBI (given only 1000 files can be deposited in each submission) and potential users' future interaction with them. For reproducibility purposes, it was necessary to deposit all 2843 files (even those not specific to this study) because ASV inference was performed on all samples (see below). This process required the use of text processing in R, given there was no explicit label for study in the filenames.

* **scripts**: `prepare_NCBIupload_filtered.R` - This complicated R script extracts sample names from the file names and then matches lists of strings specific to each known project to sort the files into studies.

* **inputs**:

 - `4_dada2/metadata_Time0D-7D-4M_May2022.csv` - This file contains the metadata of the samples, and is used to select/sort the samples Alberto used for analysis downstream of DADA2.

 - `1_raw/geographical_attributes.csv` - This contains the geographical information on the samples (particularly GPS locations) needed for the BioSample Attributes table needed as part of the NCBI deposit.

 - `3_filtered/` - Filenames of all the 2843 filtered sequence files, which are unsorted in the `3_filtered` folder after DADA2 filtering (step 3).

* **outputs**: `3_filtered/`

  - **8 sub-folders**  pertaining to 5 groups of samples for this study (organised by sampling day/rep), 1 group of samples for the Scheuerl study, 1 group of samples for the Mombrikotb study, and 1 group of miscellaneous samples (duplicate files, 'core' communities, and samples from unknown studies)
  - **8 NCBI dataframes** (e.g. NCBI_thisstudy_day0.csv) containing the basic metadata for each of the 8 groups of files that feeds into the final BioSample Attributes/SRA metadata Excel files needed for the NCBI deposit.


  8 NCBI BioSample Attributes/SRA metadata Excel files  were then manually made based on the NCBI dataframes outputted from the code, to enable the sequences to be deposited at NCBI. These are in the 8 sub-folders in the directory.

#### _Reproducible pipeline_

##### 1. ASV inference

The bioinformatic pipeline is reproducible from the post-filtering point, using the filtered sequence files deposited at NCBI under BioProject accession number PRJNA989519. To start this process, users must first download all the filtered sequence files from NCBI in the 8 submissions to each of their respective 8 sub-folders. All 2843 files from the 8 submissions must be downloaded to fully reproduce the pipeline because ASV inference was performed on the entire set of samples [1]. Users can work with just the samples from this study if they wish, but should be aware that the results may be slightly different.

After the files have been downloaded, users should open `ReplayEcology.RProj` in the home directory to open the project in RStudio. Finally, users should check they are running R version 4.1 and DADA2 version 3.14 (if not, they may need to install and load them - this can be done for DADA2 v3.14 using the hashed-out lines of the script 5-8) before running ASV (amplicon sequence variant) inference as follows.

* **scripts**: `dada2_infer_ASVs.R` - This is the script used to infer ASVs from the filtered sequences. Following the standard DADA2 pipeline, the script learns the error rate of the 2843 sequences, infers ASVs, constructs a sequence table, removes chimeras, assigns taxonomy to the chimera-free ASVs, and then writes a metadata table for the samples.

* **inputs**:

  - `3_filtered` - Filenames of all the 2843 downloaded filtered sequence files, which are organised into 8 sub-folders.

  - `4_dada2/silva_nr99_v138.1_train_set.fa.gz` - SILVA database v138.1 of sequences aligned to taxonomy, used for assigning taxonomy to ASVs to genus level.

  - `4_dada2/silva_species_assignment_v138.1.fa.gz` - SILVA database v138.1 of sequences aligned to taxonomy at species level, used for assigning taxonomy to ASVs at species level.

* **outputs**: `4_dada2/`

  - `err.RDS` - Error rate information needed as the input to dada2::dada(). This is the output of dada2::learnErrors().

  - `dada_output.RDS` - Output of the main dada2 ASV inference function dada2::dada().

  - `seqtab.RDS/csv` - ASV vs samples table, the output of the dada2 function dada2::makeSequenceTable().

  - `seqtab_nochim.RDS/csv` - ASV vs samples table, containing 75,035 ASVs from 2843 samples, the output of the dada2 function dada2::removeBimeraDenovo().

  - `taxa.RDS.csv` - Table containing inferred taxonomy of the ASVs, the output of the dada2 function dada2::assignTaxonomy().

  - `taxa_wsp.RDS/csv` - Table containing inferred species-level taxonomy of the 1480 ASVs, the output of the dada2 function dada2::assignTaxonomy().

##### 2. Matching and filtering of samples for analysis in this study

* **scripts**: `match_sets_and_filter.R` - This script performs an initial filtering of the sequence table down to those samples that contain the names of communities used in this study (see note in 'outputs' below). It then filters out the least abundant ASVs (to reduce number of ASVs/spurious ASVs), and removes samples with less than 10K sequences, in line with our previous work.

* **inputs**:

  - `seqtab_nochim.RDS` - ASV vs samples table, containing 75,035 ASVs from 2843 samples, the output of the dada2 function dada2::removeBimeraDenovo().

  - `taxa_wsp.RDS/csv` - Table containing inferred species-level taxonomy of the 75,035 ASVs, the output of the dada2 function dada2::assignTaxonomy().

  - `4_dada2/metadata_Time0D-7D-4M_May2022.csv` - This file contains the metadata of the samples, and is used to select/sort the samples APG used for analysis downstream of DADA2.

* **outputs**:

  - `seqtab_matchedandfiltered.RDS/csv` - ASV vs samples table, restricted to the 2156 treehole communities (rows) and 1480 ASVs remaining after matching and filtering. Please not that this is not the final set of communities upon which APG's analysis was performed, since this initial filtering also picked up some samples from the Scheuerl study (which used some of the same communities with the same IDs). APG therefore performed a further filtering step downstream.

  - `taxa_wsp_matchedandfiltered.RDS/csv` - Table containing inferred species-level taxonomy of the 1480 remaining ASVs, matched with ASVs in seqtable.

##### 3. Removal of chloroplasts

After matching and filtering, some ASVs were identified that were taxonomically assigned to chloroplasts or mitochondria, and hence were removed before downstream analysis.

* **scripts**: `remove_Chloroplasts.R` - This script removes chloroplast and mitochondrial ASVs before writing the final ASV tables.

* **inputs**:

  - `seqtab_matchedandfiltered.RDS/csv` - ASV vs samples table, restricted to the 2156 treehole communities (rows) and 1480 ASVs remaining after matching and filtering.

  - `taxa_wsp_matchedandfiltered.RDS/csv` - Table containing inferred species-level taxonomy of the 1480 ASVs remaining after matching and filtering.

  - `ASVs_Chloroplasts.list` - List of chloroplast ASVS
  - `ASVs_Mitochondria.list` - List of mitochondrial ASVS

* **outputs**:

  - `seqtable_readyforanalysis.RDS/csv` - ASV vs samples table of 1454 ASVs, after removal of 12 chloroplasts and 14 mitochondria ASVs. Please not that this is not the final set of communities upon which APG's analysis was performed, since this initial filtering also picked up some samples from the Scheuerl study (which used some of the same communities with the same IDs). APG therefore performed a further filtering step downstream.

  - `taxa_wsp_readyforanalysis.RDS/csv` - Table containing inferred species-level taxonomy of the 1454 ASVs remaining after chlroplast/mitochondria removal.

### Data analysis pipeline

The data analysis pipeline is not as linear as the bioinformatic one. Therefore, the structure of directories is not linear and each main script presented here may have auxiliary scripts, with most outputs being figures. Please consider the explanations available in scripts' headers, including inputs, outputs and dependencies. Scripts were coded considering the structure of the repository, so there is no need to modify the paths, hence are hard-coded relative to the root of the repository. Please note that to make the scripts portable,  R Projects and/or some functions to recover the user's path are used which, in the case of R scripts, require executing the script from RStudio. Some scripts have different options for the analysis, indicated in variables. 

#### Determination of classes
* `main_find_classes.R` Computes the all-against-all JSD for all samples and looks for the optimal partition (output in `7.1_classes`).
* `main_find_classes_exp-split.R` Same analysis for each experiment and replicate independently (output in `7.1_classes`).
* `merge_metadata.R` Script to merge metadata tables obtained with the previous scripts (output in `7.1_classes`).
* `compare_classes.R` Generates a heatmap of the mean beta-diversity of each class and cluster classes (output in `7.1_classes`).

#### Comparison of classes 
* `match_classes.R` and `TraceSamples_fromPartTime0toPartTime7.pl` Performs statistics between starting and final classes (output in `7.2_match`).
* `match_clusters_time0to7_V2.R` Represent the above statistics (output in `7.2_match`).

#### Representation of classes, statistical significance and dimensionality reduction
* `phyloseq_analysis.R` Creates bar plots for the different classes and some ordinations (output in `7.3_phyloseq`).
* `anosimlike_analysis.R` Provides a quantitative estimation of samples' similarity between the different categorical groups through the ANOSIM statistics (output in `7.4_variance`)

#### Analysis of the compositional landscape
* `distance_to_attractor.R` Provides a quantitative estimation for the probability of having all replicates in the same class as a function of the distance to the nearest attractor of the final classes (output in `7.5_attractors`).
* `represent_attractors.R` Some visualizations of the results obtained with `distance_to_attractor.R` (output in `7.5_attractors`).

#### Propensities analysis
* `propensities.R` This script first classifies communities in different trajectories, taking into account if each starting communities has its four replicates ending up in the  same final class (convergent trajectory) or not (divergent). Then, for each ASV, it estimates the statistical propensity of being observed in each type of trajectory. This estimation is made independently for starting and final communities. (output in `7.6_keystone/propensities`)

#### Analysis of PiCRUST
Please note that metagenomes predictions were obtained with PiCRUST 2 following a standard pipeline.
* `pathways_to_heatmap.R` Creates some plots of PICRUSt results (output in `8_PICRUSt`).

#### Communities superposition
* `community_superposition.R` Looks for the optimal superposition between starting communities and one of the replicates, performs a prediction and compares with the remaining replicates (output in `9_predictions`).

### Notes

1. Sequences associated with this paper are deposited at NCBI under BioProject accession number PRJNA989519. This project contains the 16S amplicon sequencing data associated with each of the communities at day 0 (SUB13586664), as well as at day 7 for the four replicate growth experiments (SUB13586665-SUB13586668). Additionally, the project contains samples associated with other projects and/or run on the same sequencing runs (SUB13586669-SUB13586671), which should also be downloaded and run through the DADA2 pipeline with the sequences related to this study, if one desires to reproduce this analysis exactly.
